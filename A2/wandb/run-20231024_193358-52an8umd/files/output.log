Image tensor shape before model call: torch.Size([4, 1, 572, 572])
Input shape to UNet: torch.Size([4, 1, 572, 572])
batch 0 --- Loss: 0.0000
Image tensor shape before model call: torch.Size([4, 1, 572, 572])
Input shape to UNet: torch.Size([4, 1, 572, 572])
batch 1 --- Loss: 0.0000
Image tensor shape before model call: torch.Size([4, 1, 572, 572])
Input shape to UNet: torch.Size([4, 1, 572, 572])
batch 2 --- Loss: 0.0000
Image tensor shape before model call: torch.Size([4, 1, 572, 572])
Input shape to UNet: torch.Size([4, 1, 572, 572])
C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3484.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
batch 3 --- Loss: 0.0000
Image tensor shape before model call: torch.Size([4, 1, 572, 572])
Input shape to UNet: torch.Size([4, 1, 572, 572])
batch 4 --- Loss: 0.0000
Image tensor shape before model call: torch.Size([4, 1, 572, 572])
Input shape to UNet: torch.Size([4, 1, 572, 572])
batch 5 --- Loss: 0.0000
Image tensor shape before model call: torch.Size([4, 1, 572, 572])
Input shape to UNet: torch.Size([4, 1, 572, 572])
batch 6 --- Loss: 0.0000
Image tensor shape before model call: torch.Size([2, 1, 572, 572])
Input shape to UNet: torch.Size([2, 1, 572, 572])
batch 7 --- Loss: 0.0000
Epoch 1 / 20 --- Loss: 0.0000
Input shape to UNet: torch.Size([4, 1, 572, 572])
Traceback (most recent call last):
  File "c:\Users\Alienware\Desktop\VC CMPT742\A2\assignment_2\train.py", line 132, in <module>
    loss = criterion(pred, label)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: only batches of spatial targets supported (3D tensors) but got targets of size: : [4, 1, 280, 572]