batch 0 --- Loss: 0.1936
batch 1 --- Loss: 0.1785
batch 2 --- Loss: 0.1541
C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3484.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
batch 3 --- Loss: 0.1183
batch 4 --- Loss: 0.0885
batch 5 --- Loss: 0.0618
batch 6 --- Loss: 0.0363
batch 7 --- Loss: 0.0274
Epoch 1 / 20 --- Loss: 0.1145
Accuracy: 1.0000 ---- Loss: 0.1156
batch 0 --- Loss: 0.0144
batch 1 --- Loss: 0.0118
batch 2 --- Loss: 0.0102
batch 3 --- Loss: 0.0061
batch 4 --- Loss: 0.0048
batch 5 --- Loss: 0.0033
batch 6 --- Loss: 0.0023
batch 7 --- Loss: 0.0023
Epoch 2 / 20 --- Loss: 0.0074
Accuracy: 1.0000 ---- Loss: 0.0244
batch 0 --- Loss: 0.0019
batch 1 --- Loss: 0.0017
batch 2 --- Loss: 0.0015
batch 3 --- Loss: 0.0014
batch 4 --- Loss: 0.0016
batch 5 --- Loss: 0.0012
batch 6 --- Loss: 0.0012
batch 7 --- Loss: 0.0011
Epoch 3 / 20 --- Loss: 0.0016
Accuracy: 1.0000 ---- Loss: 0.0028
batch 0 --- Loss: 0.0011
batch 1 --- Loss: 0.0010
batch 2 --- Loss: 0.0010
batch 3 --- Loss: 0.0010
batch 4 --- Loss: 0.0009
batch 5 --- Loss: 0.0009
batch 6 --- Loss: 0.0008
batch 7 --- Loss: 0.0008
Epoch 4 / 20 --- Loss: 0.0010
Accuracy: 1.0000 ---- Loss: 0.0011
batch 0 --- Loss: 0.0008
batch 1 --- Loss: 0.0007
batch 2 --- Loss: 0.0007
batch 3 --- Loss: 0.0007
batch 4 --- Loss: 0.0007
batch 5 --- Loss: 0.0006
batch 6 --- Loss: 0.0006
batch 7 --- Loss: 0.0006
Epoch 5 / 20 --- Loss: 0.0007
Accuracy: 1.0000 ---- Loss: 0.0006
batch 0 --- Loss: 0.0006
batch 1 --- Loss: 0.0005
batch 2 --- Loss: 0.0005
batch 3 --- Loss: 0.0005
batch 4 --- Loss: 0.0005
batch 5 --- Loss: 0.0005
batch 6 --- Loss: 0.0005
batch 7 --- Loss: 0.0004
Epoch 6 / 20 --- Loss: 0.0005
Accuracy: 1.0000 ---- Loss: 0.0004
batch 0 --- Loss: 0.0004
batch 1 --- Loss: 0.0004
batch 2 --- Loss: 0.0004
batch 3 --- Loss: 0.0004
batch 4 --- Loss: 0.0004
batch 5 --- Loss: 0.0004
batch 6 --- Loss: 0.0003
batch 7 --- Loss: 0.0003
Epoch 7 / 20 --- Loss: 0.0004
Accuracy: 1.0000 ---- Loss: 0.0003
batch 0 --- Loss: 0.0003
batch 1 --- Loss: 0.0003
batch 2 --- Loss: 0.0003
batch 3 --- Loss: 0.0003
batch 4 --- Loss: 0.0003
batch 5 --- Loss: 0.0003
batch 6 --- Loss: 0.0003
batch 7 --- Loss: 0.0003
Epoch 8 / 20 --- Loss: 0.0003
Accuracy: 1.0000 ---- Loss: 0.0003
batch 0 --- Loss: 0.0003
batch 1 --- Loss: 0.0002
batch 2 --- Loss: 0.0002
batch 3 --- Loss: 0.0002
batch 4 --- Loss: 0.0002
batch 5 --- Loss: 0.0002
batch 6 --- Loss: 0.0002
batch 7 --- Loss: 0.0002
Epoch 9 / 20 --- Loss: 0.0002
Accuracy: 1.0000 ---- Loss: 0.0002
batch 0 --- Loss: 0.0002
batch 1 --- Loss: 0.0002
batch 2 --- Loss: 0.0002
batch 3 --- Loss: 0.0002
batch 4 --- Loss: 0.0002
batch 5 --- Loss: 0.0002
batch 6 --- Loss: 0.0002
batch 7 --- Loss: 0.0002
Epoch 10 / 20 --- Loss: 0.0002
Accuracy: 1.0000 ---- Loss: 0.0002
batch 0 --- Loss: 0.0002
batch 1 --- Loss: 0.0002
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 11 / 20 --- Loss: 0.0002
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 12 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 13 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 14 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 15 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 16 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 17 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0000
batch 2 --- Loss: 0.0000
batch 3 --- Loss: 0.0000
batch 4 --- Loss: 0.0000
batch 5 --- Loss: 0.0000
batch 6 --- Loss: 0.0000
batch 7 --- Loss: 0.0000
Epoch 18 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0000
batch 0 --- Loss: 0.0000
batch 1 --- Loss: 0.0000
batch 2 --- Loss: 0.0000
batch 3 --- Loss: 0.0000
batch 4 --- Loss: 0.0000
batch 5 --- Loss: 0.0000
batch 6 --- Loss: 0.0000
batch 7 --- Loss: 0.0000
Epoch 19 / 20 --- Loss: 0.0000
Accuracy: 1.0000 ---- Loss: 0.0000
batch 0 --- Loss: 0.0000
batch 1 --- Loss: 0.0000
batch 2 --- Loss: 0.0000
batch 3 --- Loss: 0.0000
batch 4 --- Loss: 0.0000
batch 5 --- Loss: 0.0000
batch 6 --- Loss: 0.0000
batch 7 --- Loss: 0.0000
Epoch 20 / 20 --- Loss: 0.0000
Accuracy: 1.0000 ---- Loss: 0.0000
Traceback (most recent call last):
  File "c:\Users\Alienware\Desktop\VC CMPT742\A2\assignment_2\train.py", line 190, in <module>
    axes[i, 0].imshow(output_labels[i])
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\__init__.py", line 1478, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\axes\_axes.py", line 5751, in imshow
    im.set_data(X)
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\image.py", line 723, in set_data
    self._A = self._normalize_image_array(A)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\image.py", line 693, in _normalize_image_array
    raise TypeError(f"Invalid shape {A.shape} for image data")
TypeError: Invalid shape (1, 564, 572) for image data