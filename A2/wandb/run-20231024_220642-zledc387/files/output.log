batch 0 --- Loss: 0.1998
batch 1 --- Loss: 0.1783
batch 2 --- Loss: 0.1531
C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3484.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
batch 3 --- Loss: 0.1184
batch 4 --- Loss: 0.0875
batch 5 --- Loss: 0.0577
batch 6 --- Loss: 0.0414
batch 7 --- Loss: 0.0284
Epoch 1 / 20 --- Loss: 0.1153
Accuracy: 1.0000 ---- Loss: 0.1138
batch 0 --- Loss: 0.0142
batch 1 --- Loss: 0.0110
batch 2 --- Loss: 0.0061
batch 3 --- Loss: 0.0070
batch 4 --- Loss: 0.0066
batch 5 --- Loss: 0.0024
batch 6 --- Loss: 0.0022
batch 7 --- Loss: 0.0020
Epoch 2 / 20 --- Loss: 0.0069
Accuracy: 1.0000 ---- Loss: 0.0203
batch 0 --- Loss: 0.0017
batch 1 --- Loss: 0.0020
batch 2 --- Loss: 0.0014
batch 3 --- Loss: 0.0013
batch 4 --- Loss: 0.0013
batch 5 --- Loss: 0.0012
batch 6 --- Loss: 0.0011
batch 7 --- Loss: 0.0011
Epoch 3 / 20 --- Loss: 0.0015
Accuracy: 1.0000 ---- Loss: 0.0016
batch 0 --- Loss: 0.0010
batch 1 --- Loss: 0.0010
batch 2 --- Loss: 0.0009
batch 3 --- Loss: 0.0009
batch 4 --- Loss: 0.0009
batch 5 --- Loss: 0.0008
batch 6 --- Loss: 0.0008
batch 7 --- Loss: 0.0008
Epoch 4 / 20 --- Loss: 0.0009
Accuracy: 1.0000 ---- Loss: 0.0007
batch 0 --- Loss: 0.0007
batch 1 --- Loss: 0.0007
batch 2 --- Loss: 0.0007
batch 3 --- Loss: 0.0007
batch 4 --- Loss: 0.0006
batch 5 --- Loss: 0.0006
batch 6 --- Loss: 0.0006
batch 7 --- Loss: 0.0006
Epoch 5 / 20 --- Loss: 0.0007
Accuracy: 1.0000 ---- Loss: 0.0005
batch 0 --- Loss: 0.0005
batch 1 --- Loss: 0.0005
batch 2 --- Loss: 0.0005
batch 3 --- Loss: 0.0005
batch 4 --- Loss: 0.0005
batch 5 --- Loss: 0.0005
batch 6 --- Loss: 0.0004
batch 7 --- Loss: 0.0004
Epoch 6 / 20 --- Loss: 0.0005
Accuracy: 1.0000 ---- Loss: 0.0004
batch 0 --- Loss: 0.0004
batch 1 --- Loss: 0.0004
batch 2 --- Loss: 0.0004
batch 3 --- Loss: 0.0004
batch 4 --- Loss: 0.0004
batch 5 --- Loss: 0.0003
batch 6 --- Loss: 0.0003
batch 7 --- Loss: 0.0003
Epoch 7 / 20 --- Loss: 0.0004
Accuracy: 1.0000 ---- Loss: 0.0003
batch 0 --- Loss: 0.0003
batch 1 --- Loss: 0.0003
batch 2 --- Loss: 0.0003
batch 3 --- Loss: 0.0003
batch 4 --- Loss: 0.0003
batch 5 --- Loss: 0.0003
batch 6 --- Loss: 0.0003
batch 7 --- Loss: 0.0002
Epoch 8 / 20 --- Loss: 0.0003
Accuracy: 1.0000 ---- Loss: 0.0002
batch 0 --- Loss: 0.0002
batch 1 --- Loss: 0.0002
batch 2 --- Loss: 0.0002
batch 3 --- Loss: 0.0002
batch 4 --- Loss: 0.0002
batch 5 --- Loss: 0.0002
batch 6 --- Loss: 0.0002
batch 7 --- Loss: 0.0002
Epoch 9 / 20 --- Loss: 0.0002
Accuracy: 1.0000 ---- Loss: 0.0002
batch 0 --- Loss: 0.0002
batch 1 --- Loss: 0.0002
batch 2 --- Loss: 0.0002
batch 3 --- Loss: 0.0002
batch 4 --- Loss: 0.0002
batch 5 --- Loss: 0.0002
batch 6 --- Loss: 0.0002
batch 7 --- Loss: 0.0002
Epoch 10 / 20 --- Loss: 0.0002
Accuracy: 1.0000 ---- Loss: 0.0002
batch 0 --- Loss: 0.0002
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 11 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 12 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 13 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 14 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 15 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0001
Epoch 16 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0001
batch 0 --- Loss: 0.0001
batch 1 --- Loss: 0.0001
batch 2 --- Loss: 0.0001
batch 3 --- Loss: 0.0001
batch 4 --- Loss: 0.0001
batch 5 --- Loss: 0.0001
batch 6 --- Loss: 0.0001
batch 7 --- Loss: 0.0000
Epoch 17 / 20 --- Loss: 0.0001
Accuracy: 1.0000 ---- Loss: 0.0000
batch 0 --- Loss: 0.0000
batch 1 --- Loss: 0.0000
batch 2 --- Loss: 0.0000
batch 3 --- Loss: 0.0000
batch 4 --- Loss: 0.0000
batch 5 --- Loss: 0.0000
batch 6 --- Loss: 0.0000
batch 7 --- Loss: 0.0000
Epoch 18 / 20 --- Loss: 0.0000
Accuracy: 1.0000 ---- Loss: 0.0000
batch 0 --- Loss: 0.0000
batch 1 --- Loss: 0.0000
batch 2 --- Loss: 0.0000
batch 3 --- Loss: 0.0000
batch 4 --- Loss: 0.0000
batch 5 --- Loss: 0.0000
batch 6 --- Loss: 0.0000
batch 7 --- Loss: 0.0000
Epoch 19 / 20 --- Loss: 0.0000
Accuracy: 1.0000 ---- Loss: 0.0000
batch 0 --- Loss: 0.0000
batch 1 --- Loss: 0.0000
batch 2 --- Loss: 0.0000
batch 3 --- Loss: 0.0000
batch 4 --- Loss: 0.0000
batch 5 --- Loss: 0.0000
batch 6 --- Loss: 0.0000
batch 7 --- Loss: 0.0000
Epoch 20 / 20 --- Loss: 0.0000
Accuracy: 1.0000 ---- Loss: 0.0000
Traceback (most recent call last):
  File "c:\Users\Alienware\Desktop\VC CMPT742\A2\assignment_2\train.py", line 176, in <module>
    pred = model(input_image)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Alienware\Desktop\VC CMPT742\A2\assignment_2\model.py", line 113, in forward
    x1, x_before_pool1 = self.down1(x)
                         ^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Alienware\Desktop\VC CMPT742\A2\assignment_2\model.py", line 45, in forward
    x_before_pool = self.conv_block(x)
                    ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Alienware\Desktop\VC CMPT742\A2\assignment_2\model.py", line 26, in forward
    x = self.conv1(x)
        ^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Alienware\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 1, 1, 572, 572]