{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S7DHV3pqERC"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIJsXYmUp8qO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import random\n",
    "\n",
    "#import any other library you need below this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmOBtE8PqH4w"
   },
   "source": [
    "### Loading data\n",
    "\n",
    "Upload the data in zip format to Colab. Then run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMLW_lgTqRcL"
   },
   "outputs": [],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UoM-TMIqTna"
   },
   "source": [
    "### Defining the Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6awOO200qYSZ"
   },
   "outputs": [],
   "source": [
    "class Cell_data(Dataset):\n",
    "  def __init__(self, data_dir, size, train = 'True', train_test_split = 0.8, augment_data = True):\n",
    "    ##########################inputs##################################\n",
    "    #data_dir(string) - directory of the data#########################\n",
    "    #size(int) - size of the images you want to use###################\n",
    "    #train(boolean) - train data or test data#########################\n",
    "    #train_test_split(float) - the portion of the data for training###\n",
    "    #augment_data(boolean) - use data augmentation or not#############\n",
    "    super(Cell_data, self).__init__()\n",
    "    # todo\n",
    "    #initialize the data class\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      # todo\n",
    "\n",
    "      #load image and mask from index idx of your data\n",
    "\n",
    "\n",
    "      #data augmentation part\n",
    "      if augment_data:\n",
    "        augment_mode = np.random.randint(0, 4)\n",
    "        if augment_mode == 0:\n",
    "          #todo \n",
    "          #flip image vertically\n",
    "        elif augment_mode == 1:\n",
    "          #todo\n",
    "          #flip image horizontally\n",
    "        elif augment_mode == 2:\n",
    "          #todo\n",
    "          #zoom image\n",
    "        else:\n",
    "          #todo\n",
    "          #rotate image\n",
    "\n",
    "      #todo\n",
    "      #return image and mask in tensors\n",
    "      \n",
    "      \n",
    "      \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo6kRDASsc5t"
   },
   "source": [
    "### Define the Model\n",
    "1. Define the Convolution blocks\n",
    "2. Define the down path\n",
    "3. Define the up path\n",
    "4. combine the down and up path to get the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcOEN68psaxF"
   },
   "outputs": [],
   "source": [
    "class twoConvBlock(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(twoConvBlock, self).__init__()\n",
    "    #todo\n",
    "    #initialize the block\n",
    "\n",
    "  def forward(self):\n",
    "    #todo\n",
    "    #implement the forward path\n",
    "\n",
    "class downStep(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(downStep, self).__init__()\n",
    "    #todo\n",
    "    #initialize the down path\n",
    "\n",
    "  def forward(self):\n",
    "    #todo\n",
    "    #implement the forward path\n",
    "\n",
    "class upStep(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(upStep, self).__init__()\n",
    "    #todo\n",
    "    #initialize the up path\n",
    "\n",
    "  def forward(self):\n",
    "    #todo\n",
    "    #implement the forward path\n",
    "\n",
    "class UNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(upStep, self).__init__()\n",
    "    #todo\n",
    "    #initialize the complete model\n",
    "\n",
    "   def forward(self):\n",
    "    #todo\n",
    "    #implement the forward path\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5-0LnQItdth"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmFg17HktfBW"
   },
   "outputs": [],
   "source": [
    "#Paramteres\n",
    "\n",
    "#learning rate\n",
    "lr = 1e-2\n",
    "\n",
    "#number of training epochs\n",
    "epoch_n = 20\n",
    "\n",
    "#input image-mask size\n",
    "image_size = 572\n",
    "#root directory of project\n",
    "root_dir = os.getcwd()\n",
    "\n",
    "#training batch size\n",
    "batch_size = 4\n",
    "\n",
    "#use checkpoint model for training\n",
    "load = False\n",
    "\n",
    "#use GPU for training\n",
    "gpu = True\n",
    "\n",
    "data_dir = os.path.join(root_dir, 'data/cells')\n",
    "\n",
    "\n",
    "trainset = Cell_data(data_dir = data_dir, size = image_size)\n",
    "trainloader = DataLoader(trainset, batch_size = 4, shuffle=True)\n",
    "\n",
    "testset = Cell_data(data_dir = data_dir, size = image_size, train = False)\n",
    "testloader = DataLoader(testset, batch_size = 4)\n",
    "\n",
    "device = torch.device('cuda:0' if gpu else 'cpu')\n",
    "\n",
    "model = UNet().to('cuda:0').to(device)\n",
    "\n",
    "if load:\n",
    "  print('loading model')\n",
    "  model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, momentum=0.99, weight_decay=0.0005)\n",
    "\n",
    "model.train()\n",
    "for e in range(epoch_n):\n",
    "  epoch_loss = 0\n",
    "  model.train()\n",
    "  for i, data in enumerate(trainloader):\n",
    "    image, label = data\n",
    "\n",
    "    image = image.unsqueeze(1).to(device)\n",
    "    label = label.long().to(device)\n",
    "\n",
    "    pred = model(image)\n",
    "\n",
    "    crop_x = (label.shape[1] - pred.shape[2]) // 2\n",
    "    crop_y = (label.shape[2] - pred.shape[3]) // 2\n",
    "\n",
    "    label = label[:, crop_x: label.shape[1] - crop_x, crop_y: label.shape[2] - crop_y]\n",
    "    \n",
    "    loss = criterion(pred, label)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    print('batch %d --- Loss: %.4f' % (i, loss.item() / batch_size))\n",
    "  print('Epoch %d / %d --- Loss: %.4f' % (e + 1, epoch_n, epoch_loss / trainset.__len__()))\n",
    "\n",
    "  torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  total_loss = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(testloader):\n",
    "      image, label = data\n",
    "\n",
    "      image = image.unsqueeze(1).to(device)\n",
    "      label = label.long().to(device)\n",
    "\n",
    "      pred = model(image)\n",
    "      crop_x = (label.shape[1] - pred.shape[2]) // 2\n",
    "      crop_y = (label.shape[2] - pred.shape[3]) // 2\n",
    "\n",
    "      label = label[:, crop_x: label.shape[1] - crop_x, crop_y: label.shape[2] - crop_y]\n",
    "\n",
    "      loss = criterion(pred, label)\n",
    "      total_loss += loss.item()\n",
    "\n",
    "      _, pred_labels = torch.max(pred, dim = 1)\n",
    "\n",
    "      total += label.shape[0] * label.shape[1] * label.shape[2]\n",
    "      correct += (pred_labels == label).sum().item()\n",
    "\n",
    "    print('Accuracy: %.4f ---- Loss: %.4f' % (correct / total, total_loss / testset.__len__()))\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT-64s70tyBw"
   },
   "source": [
    "### Testing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko9zFomNuCfC"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "output_masks = []\n",
    "output_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for i in range(testset.__len__()):\n",
    "    image, labels = testset.__getitem__(i)\n",
    "    \n",
    "    input_image = image.unsqueeze(0).unsqueeze(0).to(device)\n",
    "    pred = model(input_image)\n",
    "\n",
    "    output_mask = torch.max(pred, dim = 1)[1].cpu().squeeze(0).numpy()\n",
    "\n",
    "    crop_x = (labels.shape[0] - output_mask.shape[0]) // 2\n",
    "    crop_y = (labels.shape[1] - output_mask.shape[1]) // 2\n",
    "    labels = labels[crop_x: labels.shape[0] - crop_x, crop_y: labels.shape[1] - crop_y].numpy()\n",
    "    \n",
    "    output_masks.append(output_mask)\n",
    "    output_labels.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OrV7k1GuFSA"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(testset.__len__(), 2, figsize = (20, 20))\n",
    "\n",
    "for i in range(testset.__len__()):\n",
    "  axes[i, 0].imshow(output_labels[i])\n",
    "  axes[i, 0].axis('off')\n",
    "  axes[i, 1].imshow(output_masks[i])\n",
    "  axes[i, 1].axis('off')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "UNet_FW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
